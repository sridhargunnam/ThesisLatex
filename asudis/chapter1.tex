\chapter{Introduction}

With the advent of AR/VR technologies there is increasing demand to capture real world content for immersive viewing experience. The real world content need to be captured from cameras and then processed to the format in which the content can be viewed in AR/VR. The main characteristics of this content is to provide immersive seamless experience where user can view in any direction as if they were teleported to that location. In order to have such immersive experiences, we need to bridge the gaps in several domains including optics, graphics, audio and video, etc. But during this project we focus on capture systems for 360 degree video. \newline

What does it means to have capture visually immersive real world scenes? Researchers \cite{cuervo2018creating} predict that we need very high resolution(16k) and framerates(120+) to make the experience visually indistinguishable from reality. Current 360 stereo video systems are used mainly designed for professional videography. They consist of several camera(18 in google's jump VR \cite{richardt2017video}) which are bulky, and capture lot of data which will is offloaded and used to generate AR/VR videos thereby limiting their usability. But in order to easily capture and share such experiences we need also need to focus on usability and portability of the devices to make 360 video mainstream in AR/VR.

We increase the usability and portability of the 360 devices if we can capture and stitch the panorama on the same devices. Most of the software use traditional algorithms fit for offloading based approaches and doesn't consider power budget for implementing 360 capture using a low power portable device. 
360 video is essential for VR, but capturing and stitching them in real-time is limited by battery life. In-order to tackle the challenge of capturing and stitching on same device, we study the system level bottlenecks in energy and performance by building a prototype. We characterize the system level bottlenecks in terms of performance per watt and latency. %[ [[condense this]
Our findings suggest that the main reason for the inefficiency is caused by building the system from off the shelf camera and traditional stitching algorithms. Conventional 360 degree is captured using a multi-camera rig and the expensive stitching is offloaded to powerful machines. Although some systems exist where stitching is done online, they are limited by output resolution, framerate and battery life. We show that the inefficiencies in the pipeline are due to lack of hardware algorithm co-design. In this paper we study the data flow of the stitching pipeline by building a protype using 6 camera system. We analyse the energy and performance bottlenecks in the pipeline and analytically evaluate the proposed optimizations. 
 
% Although commercial 360 degree solutions exist, they are mostly used for capture and stitching is offloaded to powerful machines. This limits the usability of 360 in VR and also portability and for heating. Our goal is therefore to build a 360 camera system that optimizes the entire pipeline both in hardware and software. We characterize the traditional pipeline and propose
%------------------------------

%Characterizing monoscopic, stereoscopic, bottlenecks, optimization

The document is organized as follows, in chapter two we discuss about the background and related work, in chapter three describe about the general stitching pipeline for VR panorama generation, and the prototype system design. In chapter four we present the evaluation results of the prototype system design. We then discuss proposed optimizations in chapter five, and conclusions in the  in chapter six.

The contributions of our work are as follows:\newline
1) Build end-to-end system for capturing 360 degree video.\newline
2) Characterize individual stage power and performance and highlight the bottlenecks in the system.\newline
3) Propose architectures to optimize end-to-end data flow and data abstractions needed at sub-system level. i.e optimizing the spatio-temporal redundancies in the capture and computation.\newline


