\begin{abstract}
	Omnidirectional cameras record the 360 degree videos of real world so that they can be later experienced in AR/VR headset. As the existing OD camera systems are built from off the shelf camera devices and uses the conventional stitching algorithms we see a potential research opportunity to close gaps between hardware and software. Many existing systems like Google Jump, Facebook Surround capture and compute on enormous amount of data consuming several hundreds of watts of power to stitch images in realtime 30fps. The main challenge in OD panorama generation is to understand the data flow across the system and to make decisions on data abstractions needed at different subcomponents to reduce the total system power.
	
	Our work focuses on characterizing the energy and latency of end-to-end Omni-directional(OD) Camera  systems. The goal is to find the bottlenecks of different components in the hardware and software pipeline and propose optimizations. 	
\end{abstract}
